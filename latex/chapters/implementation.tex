\section{Implementation}

This pipeline was developed in MATLAB. Since the group consisted of four students, a Git repository was used to be able to work on different files simultaneously, and to enable version control.

\subsubsection{Coordinate Frames}
In this mini project the coordinate frames were defined as shown in \cref{img_coord_frames}. The camera coordinates are in a way oriented, that the x-y plane lies parallel to the image plane, while the z-axis is pointing towards the scenery. The world frame however is oriented in such a way that the x-y plane is parallel to the ground and the z-axis is pointing upwards. The origin of the world frame is at the same location as the origin of the first bootstrap image.

Transformation between frames are described by homogenous transformation matrices. $T_{AB}$ maps points from frame $B$ to frame $A$.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{impl/coord_frames}
	\caption{Coordinate Frames}
	\label{img_coord_frames}
\end{figure}

\subsubsection{Pipeline overview}
As shown in \cref{img_flow_rough} the pipeline consists of two parts:
\begin{compactenum}
	\item Bootstraping \& Initialization
	\item Continuous operation
\end{compactenum}

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{impl/rough_chart}
	\caption{Overview flow chart}
	\label{img_flow_rough}
\end{figure}

\subsubsection{Conventions}
\begin{compactitem}
	\item Index of previous frame: $i$
	\item Index of current frame: $j$
	\item Index of frame for newly added candidate keypoint: $first$
	\item Pose difference between previous to current frame: $T_{C_iC_j}$
	\item $\left[u/v\right]$: Pixel coordinates
	\item Query keypoints: Keypoints newly generated in frame $j$ 
	\item Candidate keypoint: A keypoint without associated landmark
	\item Harris Matcher: Descriptor matching keypoint tracker (based on Harris features) developed during the lecture.
\end{compactitem}

\subsubsection{Options and parameters}
The pipeline was designed in a modular way. Key algorithms are abstracted into self-contained functions, as described in the pipeline overview. Next to this 'functional programming' approach all the tuning variables (e.g. number of keypoints, bearing angle thresholds, etc.) were centrally aggregated in a parameter struct.\\
For further insight please consult the function \code{loadParameters.m}.\\

In order to run the visual odometry two launch procedures where implemented:
\begin{compactitem}
	\item \textbf{Debug Mode:} For development and debug mode the main.m with default 		parameters can be executed. Numerous individual plots are displayed with insightful 		information about matching, inlier rejection and triangulation.
	\item \textbf{Simple GUI:} Out of performance reasons a more compact and user-friendly display of the pipeline output was created with a GUI designed with the Matlab GUIDE application, see figure \cref{img_gui}. Only the most crucial entities, like number of landmarks, are visualized for intuitive understanding.\\
\end {compactitem}

\textbf{How to run the GUI}
Please follow the steps below to run the visual odometry through the GUI environment:
\begin{compactenum}
	\item adapt dataset paths in \code{loadParameters.m}
	\item type into MATLAB command window: \code{gui\_simple}
	\item in \textit{Parameters} panel select dataset to run on and toggle respective radio buttons
	\item hit \textit{Run} to trigger the visual odometry\\
\end{compactenum}

Advanced parameter tuning can be achieved by changing the default parameters in \code{loadParameters.m}.

%\@ Miro please add pic of gui during operation
\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{gui_nice}
	\captionsetup{justification=centering}
	\caption{Graphical user interface \\candidate keypoints (red $\bullet$), inlier keypoints (green $\bullet$), reprojected landmarks (green $\times$)}
	\label{img_gui}
\end{figure}


\subsubsection{Camera calibration}
Using the Camera Calibration Toolbox for Matlab\footnote{\url{www.vision.caltech.edu/bouguetj/calib_doc/}} from Jean-Yves Bouguet (Caltech) the camera of the an iphone 7 Plus was calibrated. A set of 17 calibration images where extracted from a calibration sequence filming a checker-board pattern from various angles.

\begin{figure}[htbp]
	\centering
	\begin{minipage}{0.4\textwidth} 
		\centering
		\includegraphics[width=0.9\textwidth]{impl/calibration_image_iphone7}
		\caption{Calibration pattern coordinate system aligned after corner selection}
		\label{img_calib}
	\end{minipage}
	%\hfill	
	\begin{minipage}{0.4\textwidth}
		\centering
		\includegraphics[width=0.9\textwidth]{impl/extrinsics}
		\caption{Relative to camera pattern poses}
		\label{img_calib} 
	\end{minipage}
\end{figure}

The camera intrinsics parameters together with a fourth-order polynomial approximation of the radial-tangential distortion were calculated based on the assumption of the skew being zero. The exact values and error margins are to be found on the Github repository.\\

Given these calibration parameters the VO pipeline was also applied on self-generated datasets called \textit{Poly-Up} and \textit{Poly-Down}. Note, that no undistortion was performed, since testing showed it to be negligible.

\input{chapters/init}
\clearpage{\pagestyle{plain}\cleardoublepage}
\input{chapters/cont}
\clearpage{\pagestyle{plain}\cleardoublepage}